import React, { useState, useRef, useEffect } from "react";
import { FaMicrophone, FaStop } from "react-icons/fa";
import "../styles/SenStudyPage.css";

const SenMicButton = ({ selectedIndex, sentences, onUploadComplete }) => {
  const [isRecording, setIsRecording] = useState(false);
  const [statusList, setStatusList] = useState([]);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  useEffect(() => {
    if (sentences.length > 0) {
      setStatusList(new Array(sentences.length).fill("ë²„íŠ¼ì„ ëˆŒëŸ¬ì„œ ë…¹ìŒí•˜ê¸°"));
    }
  }, [sentences]);

  const updateStatus = (index, message) => {
    setStatusList((prev) => {
      const updated = [...prev];
      updated[index] = message;
      return updated;
    });
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const audioContext = new AudioContext({ sampleRate: 16000 });
      const source = audioContext.createMediaStreamSource(stream);
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      source.connect(processor);
      processor.connect(audioContext.destination);

      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          audioChunksRef.current.push(e.data);
        }
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(audioChunksRef.current, { type: "audio/wav" });
        uploadAudio(blob);
      };

      mediaRecorder.start();
      setIsRecording(true);
      updateStatus(selectedIndex, "ğŸ™ï¸ ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤...");
    } catch (err) {
      console.error("âŒ ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜", err);
      updateStatus(selectedIndex, "âŒ ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜");
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      updateStatus(selectedIndex, "");
    }
  };

  const uploadAudio = async (audioBlob) => {
    const sentence = sentences[selectedIndex];

    if (!sentence || !sentence.id || isNaN(sentence.id)) {
      console.error("â— ìœ íš¨í•˜ì§€ ì•Šì€ sentence ê°ì²´ ë˜ëŠ” ID:", sentence);
      updateStatus(selectedIndex, "âŒ ë¬¸ì¥ ì •ë³´ ì˜¤ë¥˜");
      return;
    }

    const sentenceId = sentence.id;
    const token = localStorage.getItem("authToken");

    if (!token) {
      alert("ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.");
      return;
    }

    const formData = new FormData();
    const filename = `${Date.now()}.wav`;
    formData.append("audio", audioBlob, filename);

    const endpoint = `http://localhost:8080/api/upload/sentence/${sentenceId}`;

    console.log("===========================");
    console.log("ğŸ¯ ì—…ë¡œë“œ ì‹œë„ ì‹œì‘");
    console.log("ğŸ†” sentenceId:", sentenceId);
    console.log("ğŸ§ íŒŒì¼ ì´ë¦„:", filename);
    console.log("ğŸ” Authorization í—¤ë”:", token);
    console.log("ğŸ“¡ ìš”ì²­ ê²½ë¡œ:", endpoint);
    console.log("===========================");

    try {
      const response = await fetch(endpoint, {
        method: "POST",
        headers: {
          Authorization: `Bearer ${token}`,
          // Content-Typeì€ FormDataì¼ ê²½ìš° ìë™ ì„¤ì •ë¨, ì‘ì„±í•˜ë©´ ì•ˆ ë¨
        },
        body: formData,
      });

      if (response.ok) {
        const result = await response.json();
        console.log("âœ… ì—…ë¡œë“œ ì„±ê³µ:", result);
        updateStatus(selectedIndex, "âœ… ì—…ë¡œë“œ ì™„ë£Œ!");
        onUploadComplete?.(result);
      } else {
        const errorText = await response.text();
        console.error("âŒ ì—…ë¡œë“œ ì‹¤íŒ¨:", response.status, errorText);
        updateStatus(selectedIndex, `âŒ ì—…ë¡œë“œ ì‹¤íŒ¨ (${response.status})`);
      }
    } catch (err) {
      console.error("âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ:", err);
      updateStatus(selectedIndex, "âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜");
    }
  };

  return (
    <div className="mic-button-container">
      <button
        className="mic-button"
        onClick={isRecording ? stopRecording : startRecording}
      >
        {isRecording ? (
          <FaStop size={50} color="#3366ff" />
        ) : (
          <FaMicrophone size={50} color="#3366ff" />
        )}
      </button>
      <p className="mic-text">{statusList[selectedIndex]}</p>
    </div>
  );
};

export default SenMicButton;
